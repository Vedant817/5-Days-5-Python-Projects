{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSZm_espAgi6",
        "outputId": "faabe7db-9e6f-4a8f-e859-cbad6170901a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in c:\\users\\vedan\\anaconda3\\lib\\site-packages (3.8.1)\n",
            "Requirement already satisfied: click in c:\\users\\vedan\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\vedan\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\vedan\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (2023.10.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\vedan\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (4.66.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\vedan\\appdata\\roaming\\python\\python311\\site-packages (from click->nltk) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su9fmvEFA6jT",
        "outputId": "8fcd5162-cf86-4bab-8057-bfdcace222b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Invalid requirement: '#'\n"
          ]
        }
      ],
      "source": [
        "pip install scikit-learn # Helps in Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YqfiZqKTBGVA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction import text\n",
        "from sklearn.metrics.pairwise import cosine_similarity # To check two movies are similar or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiDcjTAQBvc7",
        "outputId": "e8ece46e-aedf-4da3-9d03-07c90b071d06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                Show Id                          Title  \\\n",
            "0  cc1b6ed9-cf9e-4057-8303-34577fb54477                       (Un)Well   \n",
            "1  e2ef4e91-fb25-42ab-b485-be8e3b23dedb                         #Alive   \n",
            "2  b01b73b7-81f6-47a7-86d8-acb63080d525  #AnneFrank - Parallel Stories   \n",
            "3  b6611af0-f53c-4a08-9ffa-9716dc57eb9c                       #blackAF   \n",
            "4  7f2d4170-bab8-4d75-adc2-197f7124c070               #cats_the_mewvie   \n",
            "\n",
            "                                         Description  \\\n",
            "0  This docuseries takes a deep dive into the luc...   \n",
            "1  As a grisly virus rampages a city, a lone man ...   \n",
            "2  Through her diary, Anne Frank's story is retol...   \n",
            "3  Kenya Barris and his family navigate relations...   \n",
            "4  This pawesome documentary explores how our fel...   \n",
            "\n",
            "                      Director  \\\n",
            "0                          NaN   \n",
            "1                       Cho Il   \n",
            "2  Sabina Fedeli, Anna Migotto   \n",
            "3                          NaN   \n",
            "4             Michael Margolis   \n",
            "\n",
            "                                           Genres  \\\n",
            "0                                      Reality TV   \n",
            "1  Horror Movies, International Movies, Thrillers   \n",
            "2             Documentaries, International Movies   \n",
            "3                                     TV Comedies   \n",
            "4             Documentaries, International Movies   \n",
            "\n",
            "                                                Cast Production Country  \\\n",
            "0                                                NaN      United States   \n",
            "1                           Yoo Ah-in, Park Shin-hye        South Korea   \n",
            "2                        Helen Mirren, Gengher Gatti              Italy   \n",
            "3  Kenya Barris, Rashida Jones, Iman Benson, Genn...      United States   \n",
            "4                                                NaN             Canada   \n",
            "\n",
            "   Release Date Rating  Duration Imdb Score Content Type         Date Added  \n",
            "0        2020.0  TV-MA  1 Season     6.6/10      TV Show                NaN  \n",
            "1        2020.0  TV-MA    99 min     6.2/10        Movie  September 8, 2020  \n",
            "2        2019.0  TV-14    95 min     6.4/10        Movie       July 1, 2020  \n",
            "3        2020.0  TV-MA  1 Season     6.6/10      TV Show                NaN  \n",
            "4        2020.0  TV-14    90 min     5.1/10        Movie   February 5, 2020  \n"
          ]
        }
      ],
      "source": [
        "netflix_df = pd.read_csv(\"./netflixData.csv\")\n",
        "print(netflix_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSCgSCpeCKnI",
        "outputId": "a07a9c6f-06f1-481e-f399-3103592686db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5967 entries, 0 to 5966\n",
            "Data columns (total 13 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   Show Id             5967 non-null   object \n",
            " 1   Title               5967 non-null   object \n",
            " 2   Description         5967 non-null   object \n",
            " 3   Director            3903 non-null   object \n",
            " 4   Genres              5967 non-null   object \n",
            " 5   Cast                5437 non-null   object \n",
            " 6   Production Country  5408 non-null   object \n",
            " 7   Release Date        5964 non-null   float64\n",
            " 8   Rating              5963 non-null   object \n",
            " 9   Duration            5964 non-null   object \n",
            " 10  Imdb Score          5359 non-null   object \n",
            " 11  Content Type        5967 non-null   object \n",
            " 12  Date Added          4632 non-null   object \n",
            "dtypes: float64(1), object(12)\n",
            "memory usage: 606.2+ KB\n"
          ]
        }
      ],
      "source": [
        "netflix_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MqzP0gUCXLJ",
        "outputId": "6333eb03-deda-4259-cf4b-ac1ff6c4c080"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Show Id  Title  Description  Director  Genres   Cast  \\\n",
            "0       False  False        False      True   False   True   \n",
            "1       False  False        False     False   False  False   \n",
            "2       False  False        False     False   False  False   \n",
            "3       False  False        False      True   False  False   \n",
            "4       False  False        False     False   False   True   \n",
            "...       ...    ...          ...       ...     ...    ...   \n",
            "5962    False  False        False     False   False  False   \n",
            "5963    False  False        False      True   False  False   \n",
            "5964    False  False        False      True   False  False   \n",
            "5965    False  False        False     False   False  False   \n",
            "5966    False  False        False     False   False  False   \n",
            "\n",
            "      Production Country  Release Date  Rating  Duration  Imdb Score  \\\n",
            "0                  False         False   False     False       False   \n",
            "1                  False         False   False     False       False   \n",
            "2                  False         False   False     False       False   \n",
            "3                  False         False   False     False       False   \n",
            "4                  False         False   False     False       False   \n",
            "...                  ...           ...     ...       ...         ...   \n",
            "5962               False         False   False     False       False   \n",
            "5963                True         False   False     False        True   \n",
            "5964                True         False   False     False        True   \n",
            "5965               False         False   False     False       False   \n",
            "5966                True         False   False     False       False   \n",
            "\n",
            "      Content Type  Date Added  \n",
            "0            False        True  \n",
            "1            False       False  \n",
            "2            False       False  \n",
            "3            False        True  \n",
            "4            False       False  \n",
            "...            ...         ...  \n",
            "5962         False       False  \n",
            "5963         False        True  \n",
            "5964         False        True  \n",
            "5965         False       False  \n",
            "5966         False       False  \n",
            "\n",
            "[5967 rows x 13 columns]\n"
          ]
        }
      ],
      "source": [
        "print(netflix_df.isnull())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5o9Ii1SCkHF",
        "outputId": "b806b341-4671-4ba9-f7ef-025df35e786f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Show Id                  0\n",
            "Title                    0\n",
            "Description              0\n",
            "Director              2064\n",
            "Genres                   0\n",
            "Cast                   530\n",
            "Production Country     559\n",
            "Release Date             3\n",
            "Rating                   4\n",
            "Duration                 3\n",
            "Imdb Score             608\n",
            "Content Type             0\n",
            "Date Added            1335\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(netflix_df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zNkbl8LtCwEA",
        "outputId": "d12decc7-737c-432c-a3ae-2e584b78ab48"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "      <th>Content Type</th>\n",
              "      <th>Genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(Un)Well</td>\n",
              "      <td>This docuseries takes a deep dive into the luc...</td>\n",
              "      <td>TV Show</td>\n",
              "      <td>Reality TV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#Alive</td>\n",
              "      <td>As a grisly virus rampages a city, a lone man ...</td>\n",
              "      <td>Movie</td>\n",
              "      <td>Horror Movies, International Movies, Thrillers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>#AnneFrank - Parallel Stories</td>\n",
              "      <td>Through her diary, Anne Frank's story is retol...</td>\n",
              "      <td>Movie</td>\n",
              "      <td>Documentaries, International Movies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#blackAF</td>\n",
              "      <td>Kenya Barris and his family navigate relations...</td>\n",
              "      <td>TV Show</td>\n",
              "      <td>TV Comedies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#cats_the_mewvie</td>\n",
              "      <td>This pawesome documentary explores how our fel...</td>\n",
              "      <td>Movie</td>\n",
              "      <td>Documentaries, International Movies</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           Title  \\\n",
              "0                       (Un)Well   \n",
              "1                         #Alive   \n",
              "2  #AnneFrank - Parallel Stories   \n",
              "3                       #blackAF   \n",
              "4               #cats_the_mewvie   \n",
              "\n",
              "                                         Description Content Type  \\\n",
              "0  This docuseries takes a deep dive into the luc...      TV Show   \n",
              "1  As a grisly virus rampages a city, a lone man ...        Movie   \n",
              "2  Through her diary, Anne Frank's story is retol...        Movie   \n",
              "3  Kenya Barris and his family navigate relations...      TV Show   \n",
              "4  This pawesome documentary explores how our fel...        Movie   \n",
              "\n",
              "                                           Genres  \n",
              "0                                      Reality TV  \n",
              "1  Horror Movies, International Movies, Thrillers  \n",
              "2             Documentaries, International Movies  \n",
              "3                                     TV Comedies  \n",
              "4             Documentaries, International Movies  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "required_nf_df = netflix_df[[\"Title\", \"Description\", \"Content Type\", \"Genres\"]]\n",
        "required_nf_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "AyF3ucEZDOYM",
        "outputId": "5bbc404d-b63e-48eb-a29d-0fb22a328193"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "      <th>Content Type</th>\n",
              "      <th>Genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(Un)Well</td>\n",
              "      <td>This docuseries takes a deep dive into the luc...</td>\n",
              "      <td>TV Show</td>\n",
              "      <td>Reality TV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#Alive</td>\n",
              "      <td>As a grisly virus rampages a city, a lone man ...</td>\n",
              "      <td>Movie</td>\n",
              "      <td>Horror Movies, International Movies, Thrillers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>#AnneFrank - Parallel Stories</td>\n",
              "      <td>Through her diary, Anne Frank's story is retol...</td>\n",
              "      <td>Movie</td>\n",
              "      <td>Documentaries, International Movies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#blackAF</td>\n",
              "      <td>Kenya Barris and his family navigate relations...</td>\n",
              "      <td>TV Show</td>\n",
              "      <td>TV Comedies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#cats_the_mewvie</td>\n",
              "      <td>This pawesome documentary explores how our fel...</td>\n",
              "      <td>Movie</td>\n",
              "      <td>Documentaries, International Movies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5962</th>\n",
              "      <td>الف مبروك</td>\n",
              "      <td>On his wedding day, an arrogant, greedy accoun...</td>\n",
              "      <td>Movie</td>\n",
              "      <td>Comedies, Dramas, International Movies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5963</th>\n",
              "      <td>دفعة القاهرة</td>\n",
              "      <td>A group of women leaves Kuwait to attend unive...</td>\n",
              "      <td>TV Show</td>\n",
              "      <td>International TV Shows, TV Dramas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5964</th>\n",
              "      <td>海的儿子</td>\n",
              "      <td>Two brothers start a new life in Singapore, wh...</td>\n",
              "      <td>TV Show</td>\n",
              "      <td>International TV Shows, TV Dramas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5965</th>\n",
              "      <td>반드시 잡는다</td>\n",
              "      <td>After people in his town start turning up dead...</td>\n",
              "      <td>Movie</td>\n",
              "      <td>Dramas, International Movies, Thrillers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5966</th>\n",
              "      <td>최강전사 미니특공대 : 영웅의 탄생</td>\n",
              "      <td>Miniforce, a special task force of elite range...</td>\n",
              "      <td>Movie</td>\n",
              "      <td>Children &amp; Family Movies</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5967 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                              Title  \\\n",
              "0                          (Un)Well   \n",
              "1                            #Alive   \n",
              "2     #AnneFrank - Parallel Stories   \n",
              "3                          #blackAF   \n",
              "4                  #cats_the_mewvie   \n",
              "...                             ...   \n",
              "5962                      الف مبروك   \n",
              "5963                   دفعة القاهرة   \n",
              "5964                           海的儿子   \n",
              "5965                        반드시 잡는다   \n",
              "5966            최강전사 미니특공대 : 영웅의 탄생   \n",
              "\n",
              "                                            Description Content Type  \\\n",
              "0     This docuseries takes a deep dive into the luc...      TV Show   \n",
              "1     As a grisly virus rampages a city, a lone man ...        Movie   \n",
              "2     Through her diary, Anne Frank's story is retol...        Movie   \n",
              "3     Kenya Barris and his family navigate relations...      TV Show   \n",
              "4     This pawesome documentary explores how our fel...        Movie   \n",
              "...                                                 ...          ...   \n",
              "5962  On his wedding day, an arrogant, greedy accoun...        Movie   \n",
              "5963  A group of women leaves Kuwait to attend unive...      TV Show   \n",
              "5964  Two brothers start a new life in Singapore, wh...      TV Show   \n",
              "5965  After people in his town start turning up dead...        Movie   \n",
              "5966  Miniforce, a special task force of elite range...        Movie   \n",
              "\n",
              "                                              Genres  \n",
              "0                                         Reality TV  \n",
              "1     Horror Movies, International Movies, Thrillers  \n",
              "2                Documentaries, International Movies  \n",
              "3                                        TV Comedies  \n",
              "4                Documentaries, International Movies  \n",
              "...                                              ...  \n",
              "5962          Comedies, Dramas, International Movies  \n",
              "5963               International TV Shows, TV Dramas  \n",
              "5964               International TV Shows, TV Dramas  \n",
              "5965         Dramas, International Movies, Thrillers  \n",
              "5966                        Children & Family Movies  \n",
              "\n",
              "[5967 rows x 4 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dropping the columns with Null Values\n",
        "required_nf_df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMqS5LwBDfn5",
        "outputId": "64c63174-9571-4375-a5c4-655fdfae320e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Title           5967\n",
              "Description     5967\n",
              "Content Type    5967\n",
              "Genres          5967\n",
              "dtype: int64"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "required_nf_df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ds0jvnwdDlNs",
        "outputId": "bf365153-93a6-49dc-eedd-e4ce6b82fdc3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Error loading stopwords: <urlopen error [WinError 10061]\n",
            "[nltk_data]     No connection could be made because the target machine\n",
            "[nltk_data]     actively refused it>\n"
          ]
        }
      ],
      "source": [
        "# Cleaning the Data\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stemmer = nltk.SnowballStemmer(\"english\") # Coverting the long words into the Root word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KFxTCzV4EfxF"
      },
      "outputs": [
        {
          "ename": "LookupError",
          "evalue": "\n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\vedan/nltk_data'\n    - 'c:\\\\Users\\\\vedan\\\\anaconda3\\\\nltk_data'\n    - 'c:\\\\Users\\\\vedan\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\vedan\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\vedan\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\vedan\\anaconda3\\Lib\\site-packages\\nltk\\corpus\\util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 84\u001b[0m     root \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mfind(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msubdir\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mzip_name\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     85\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\vedan\\anaconda3\\Lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(resource_not_found)\n",
            "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords.zip/stopwords/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\vedan/nltk_data'\n    - 'c:\\\\Users\\\\vedan\\\\anaconda3\\\\nltk_data'\n    - 'c:\\\\Users\\\\vedan\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\vedan\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\vedan\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\vedan\\Documents\\Resources\\5 Days 5 Python Projects\\Movie Recommendation System\\Movie_Recommendation.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vedan/Documents/Resources/5%20Days%205%20Python%20Projects/Movie%20Recommendation%20System/Movie_Recommendation.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcorpus\u001b[39;00m \u001b[39mimport\u001b[39;00m stopwords\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vedan/Documents/Resources/5%20Days%205%20Python%20Projects/Movie%20Recommendation%20System/Movie_Recommendation.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mstring\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/vedan/Documents/Resources/5%20Days%205%20Python%20Projects/Movie%20Recommendation%20System/Movie_Recommendation.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m stopword \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(stopwords\u001b[39m.\u001b[39;49mwords(\u001b[39m'\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m'\u001b[39m))\n",
            "File \u001b[1;32mc:\\Users\\vedan\\anaconda3\\Lib\\site-packages\\nltk\\corpus\\util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__bases__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    119\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLazyCorpusLoader object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m__bases__\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__load()\n\u001b[0;32m    122\u001b[0m \u001b[39m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39m# __class__ to something new:\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, attr)\n",
            "File \u001b[1;32mc:\\Users\\vedan\\anaconda3\\Lib\\site-packages\\nltk\\corpus\\util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m             root \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfind(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubdir\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mzip_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     85\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m             \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m     88\u001b[0m \u001b[39m# Load the corpus.\u001b[39;00m\n\u001b[0;32m     89\u001b[0m corpus \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__reader_cls(root, \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__kwargs)\n",
            "File \u001b[1;32mc:\\Users\\vedan\\anaconda3\\Lib\\site-packages\\nltk\\corpus\\util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     80\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m         root \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mfind(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msubdir\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__name\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     82\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     83\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\vedan\\anaconda3\\Lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m sep \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m70\u001b[39m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(resource_not_found)\n",
            "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\vedan/nltk_data'\n    - 'c:\\\\Users\\\\vedan\\\\anaconda3\\\\nltk_data'\n    - 'c:\\\\Users\\\\vedan\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\vedan\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\vedan\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "stopword = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyfR0LFQFW9O"
      },
      "outputs": [],
      "source": [
        "import re # Regular Expression\n",
        "\n",
        "def clean(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    text = [word for word in text.split(' ') if word not in stopword]\n",
        "    text=\" \".join(text)\n",
        "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
        "    text=\" \".join(text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v82bU-nWF76b",
        "outputId": "01dd574c-707a-4aeb-d3d0-4c4e9b76920d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-21c0b3ed5d0d>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  required_nf_df['Title'] = required_nf_df['Title'].apply(clean)\n"
          ]
        }
      ],
      "source": [
        "required_nf_df['Title'] = required_nf_df['Title'].apply(clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQiHVSSPGM-S",
        "outputId": "81711137-a566-4cd0-f78b-c6c65882607d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0                           unwel\n",
            "1                            aliv\n",
            "2       annefrank  parallel stori\n",
            "3                         blackaf\n",
            "4                    catsthemewvi\n",
            "                  ...            \n",
            "5962                    الف مبروك\n",
            "5963                 دفعة القاهرة\n",
            "5964                         海的儿子\n",
            "5965                      반드시 잡는다\n",
            "5966           최강전사 미니특공대  영웅의 탄생\n",
            "Name: Title, Length: 5967, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(required_nf_df['Title'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzCIPHKyGedE"
      },
      "outputs": [],
      "source": [
        "genreList = required_nf_df['Genres'].tolist()\n",
        "tfidf = text.TfidfVectorizer(stop_words = \"english\")\n",
        "tfidf_matrix = tfidf.fit_transform(genreList)\n",
        "similarity = cosine_similarity(tfidf_matrix) # We find the Cosine angle between the words and if the angle comes out to be 0 degrees then the words are similar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hG47pNi5HjcG"
      },
      "outputs": [],
      "source": [
        "indices = pd.Series(required_nf_df.index, index= required_nf_df[\"Title\"]).drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nysbttk1H5vA"
      },
      "outputs": [],
      "source": [
        "# Algorithm\n",
        "def netflix_recommendation(title, similarity=similarity):\n",
        "  index = indices[title]\n",
        "  similarity_score = list(enumerate(similarity[index]))\n",
        "  similarity_score = similarity_score[0:10]\n",
        "  movie_indices=[i[0] for i in similarity_score]\n",
        "  return required_nf_df['Title'].iloc[movie_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owGg4kygI0WN",
        "outputId": "ced0df6d-8158-4ac2-9ec3-6a9a5361a63e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0                        unwel\n",
            "1                         aliv\n",
            "2    annefrank  parallel stori\n",
            "3                      blackaf\n",
            "4                 catsthemewvi\n",
            "5               friendbutmarri\n",
            "6              friendbutmarri \n",
            "7                  realityhigh\n",
            "8                             \n",
            "9                        selfi\n",
            "Name: Title, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(netflix_recommendation('fitoor'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWBqH-gcJA8u"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
